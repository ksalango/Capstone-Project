{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac380faa-6705-4c9e-a5b1-12528f34a8ec",
   "metadata": {},
   "source": [
    "# Forecasting with XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57fdbd-b532-4ac1-a3b0-d15bfd39cc43",
   "metadata": {},
   "source": [
    "**Introduction/Methodology/DataDict**\n",
    "\n",
    "Methodology:\n",
    "A Random Forest Model will be used to try to forecast wave height and wave period. First a dataframe will be created, containing lagged features as well as cyclic encoded variables for month season and week. \n",
    "Moon phase added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "214a49fe-98af-4da5-8544-ce7d49f38b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import decimal\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70779be-c8d3-436c-96f5-72e056f90cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Data/df_daily_imputed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6dc92e-5ae7-41db-a6a3-2583ba1eb1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9902 entries, 1988-11-22 to 2016-01-01\n",
      "Data columns (total 33 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   LATITUDE   9902 non-null   float64\n",
      " 1   LONGITUDE  9902 non-null   float64\n",
      " 2   DEPTH      9902 non-null   float64\n",
      " 3   VWH$       9902 non-null   float64\n",
      " 4   VCMX       9902 non-null   float64\n",
      " 5   VTP$       9902 non-null   float64\n",
      " 6   WDIR       9902 non-null   float64\n",
      " 7   WSPD       9902 non-null   float64\n",
      " 8   GSPD       9902 non-null   float64\n",
      " 9   WDIR.1     9902 non-null   float64\n",
      " 10  WSPD.1     9902 non-null   float64\n",
      " 11  GSPD.1     9902 non-null   float64\n",
      " 12  ATMS       9902 non-null   float64\n",
      " 13  DRYT       9902 non-null   float64\n",
      " 14  SSTP       9902 non-null   float64\n",
      " 15  YEAR       9902 non-null   float64\n",
      " 16  WD         9902 non-null   float64\n",
      " 17  WS         9902 non-null   float64\n",
      " 18  ETOT       9902 non-null   float64\n",
      " 19  TP         9902 non-null   float64\n",
      " 20  VMD        9902 non-null   float64\n",
      " 21  ETTSea     9902 non-null   float64\n",
      " 22  TPSea      9902 non-null   float64\n",
      " 23  VMDSea     9902 non-null   float64\n",
      " 24  ETTSw      9902 non-null   float64\n",
      " 25  TPSw       9902 non-null   float64\n",
      " 26  VMDSw      9902 non-null   float64\n",
      " 27  MO1        9902 non-null   float64\n",
      " 28  MO2        9902 non-null   float64\n",
      " 29  HS         9902 non-null   float64\n",
      " 30  DMDIR      9902 non-null   float64\n",
      " 31  ANGSPR     9902 non-null   float64\n",
      " 32  INLINE     9902 non-null   float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc5161-a2f8-4c2a-b86f-064bba7b8903",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008e1891-eccb-4c98-99e9-9d0ac1f5f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert directions(degrees North) into radians\n",
    "columns_to_convert = ['VMD', 'VMDSea', 'VMDSw', 'WD', 'WDIR', 'WDIR.1']\n",
    "\n",
    "# Convert specified columns to radians\n",
    "df[columns_to_convert] = np.radians(df[columns_to_convert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47ec27e-851a-49e5-ac0a-5c56867b79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               LATITUDE  LONGITUDE  DEPTH      VWH$      VCMX       VTP$  \\\n",
      "Datetime_buoy                                                              \n",
      "1989-02-20        48.83      126.0   73.0  2.000417  3.683333  12.922500   \n",
      "1989-02-21        48.83      126.0   73.0  2.281739  3.926087  13.330435   \n",
      "1989-02-22        48.83      126.0   73.0  2.645000  4.691667  10.620833   \n",
      "1989-02-23        48.83      126.0   73.0  2.488750  4.337500  10.010000   \n",
      "1989-02-24        48.83      126.0   73.0  2.564583  4.475000  12.950833   \n",
      "\n",
      "                   WDIR       WSPD       GSPD    WDIR.1  ...  \\\n",
      "Datetime_buoy                                            ...   \n",
      "1989-02-20     2.070397   9.537500  11.558333  1.914772  ...   \n",
      "1989-02-21     2.057971  10.847826  13.182609  1.891026  ...   \n",
      "1989-02-22     2.600541   8.416667  10.287500  2.431098  ...   \n",
      "1989-02-23     2.953970   5.193750   6.987500  2.781618  ...   \n",
      "1989-02-24     1.845686   5.983333   7.516667  1.693697  ...   \n",
      "\n",
      "               DMDIR_lag_1_month  DMDIR_lag_3_month  ANGSPR_lag_1_day  \\\n",
      "Datetime_buoy                                                           \n",
      "1989-02-20             94.429252          67.000000          0.797225   \n",
      "1989-02-21            101.572331          52.469565          0.832525   \n",
      "1989-02-22             96.107692          75.142857          0.773209   \n",
      "1989-02-23            163.115000          87.786957          0.637375   \n",
      "1989-02-24            154.975000          89.922727          0.684806   \n",
      "\n",
      "               ANGSPR_lag_1_week  ANGSPR_lag_1_month  ANGSPR_lag_3_month  \\\n",
      "Datetime_buoy                                                              \n",
      "1989-02-20              0.641100            0.738620            0.807500   \n",
      "1989-02-21              0.604950            0.732446            0.771422   \n",
      "1989-02-22              0.658125            0.833238            0.850457   \n",
      "1989-02-23              0.652967            0.718400            0.859587   \n",
      "1989-02-24              0.540887            0.708788            0.819845   \n",
      "\n",
      "               INLINE_lag_1_day  INLINE_lag_1_week  INLINE_lag_1_month  \\\n",
      "Datetime_buoy                                                            \n",
      "1989-02-20             0.730675           0.660987            0.727566   \n",
      "1989-02-21             0.738725           0.615088            0.726329   \n",
      "1989-02-22             0.684091           0.612550            0.756046   \n",
      "1989-02-23             0.630088           0.541333            0.702125   \n",
      "1989-02-24             0.583431           0.617443            0.668312   \n",
      "\n",
      "               INLINE_lag_3_month  \n",
      "Datetime_buoy                      \n",
      "1989-02-20               0.715300  \n",
      "1989-02-21               0.673013  \n",
      "1989-02-22               0.765200  \n",
      "1989-02-23               0.789322  \n",
      "1989-02-24               0.757150  \n",
      "\n",
      "[5 rows x 165 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/3457223367.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n"
     ]
    }
   ],
   "source": [
    "# Define lags for different time intervals\n",
    "lags = {'1_day': 1, '1_week': 7, '1_month': 30, '3_month': 90}\n",
    "\n",
    "\n",
    "# Create a new DataFrame to avoid modifying the original DataFrame in place\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# Create lags, rolling averages, and std deviations for all numeric columns\n",
    "for column in df.select_dtypes(include='number').columns:\n",
    "    # Create lags for different time intervalsa\n",
    "    for lag_name, lag_value in lags.items():\n",
    "        new_df[f'{column}_lag_{lag_name}'] = df[column].shift(lag_value)\n",
    "\n",
    "\n",
    "# Combine the new features with the original DataFrame\n",
    "features_df = pd.concat([df, new_df], axis=1)\n",
    "\n",
    "# Drop rows with null values\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbbb199-db8f-4509-88c4-8e9857d28025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9812, 165)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c133696d-2308-461f-909d-29bcd2bc5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.index = pd.to_datetime(features_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa471d34-07f8-48af-87a0-033eb9a0d5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>VWH$</th>\n",
       "      <th>VCMX</th>\n",
       "      <th>VTP$</th>\n",
       "      <th>WDIR</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>GSPD</th>\n",
       "      <th>WDIR.1</th>\n",
       "      <th>...</th>\n",
       "      <th>ANGSPR_lag_1_month</th>\n",
       "      <th>ANGSPR_lag_3_month</th>\n",
       "      <th>INLINE_lag_1_day</th>\n",
       "      <th>INLINE_lag_1_week</th>\n",
       "      <th>INLINE_lag_1_month</th>\n",
       "      <th>INLINE_lag_3_month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>season_sin</th>\n",
       "      <th>season_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime_buoy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-02-20</th>\n",
       "      <td>48.83</td>\n",
       "      <td>126.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.000417</td>\n",
       "      <td>3.683333</td>\n",
       "      <td>12.9225</td>\n",
       "      <td>2.070397</td>\n",
       "      <td>9.5375</td>\n",
       "      <td>11.558333</td>\n",
       "      <td>1.914772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73862</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>0.730675</td>\n",
       "      <td>0.660987</td>\n",
       "      <td>0.727566</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14112</td>\n",
       "      <td>0.989992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               LATITUDE  LONGITUDE  DEPTH      VWH$      VCMX     VTP$  \\\n",
       "Datetime_buoy                                                            \n",
       "1989-02-20        48.83      126.0   73.0  2.000417  3.683333  12.9225   \n",
       "\n",
       "                   WDIR    WSPD       GSPD    WDIR.1  ...  ANGSPR_lag_1_month  \\\n",
       "Datetime_buoy                                         ...                       \n",
       "1989-02-20     2.070397  9.5375  11.558333  1.914772  ...             0.73862   \n",
       "\n",
       "               ANGSPR_lag_3_month  INLINE_lag_1_day  INLINE_lag_1_week  \\\n",
       "Datetime_buoy                                                            \n",
       "1989-02-20                 0.8075          0.730675           0.660987   \n",
       "\n",
       "               INLINE_lag_1_month  INLINE_lag_3_month  month_sin  month_cos  \\\n",
       "Datetime_buoy                                                                 \n",
       "1989-02-20               0.727566              0.7153   0.866025        0.5   \n",
       "\n",
       "               season_sin  season_cos  \n",
       "Datetime_buoy                          \n",
       "1989-02-20        0.14112    0.989992  \n",
       "\n",
       "[1 rows x 169 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8685a6f-1947-4501-bcdb-ca85ef91dae1",
   "metadata": {},
   "source": [
    "**Cyclic Encode Temporal Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aea449e3-9ecb-4991-82d0-d4b5fa9ffa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/5589926.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df['week_sin'] = np.sin(2 * np.pi * features_df.index.strftime('%U').astype(int) / 52)  # Assuming 52 weeks in a year\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/5589926.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df['week_cos'] = np.cos(2 * np.pi * features_df.index.strftime('%U').astype(int) / 52)\n"
     ]
    }
   ],
   "source": [
    "#Create cyclical encoded features for month, season, and week\n",
    "features_df['month_sin'] = np.sin(2 * np.pi * features_df.index.month / 12)\n",
    "features_df['month_cos'] = np.cos(2 * np.pi * features_df.index.month / 12)\n",
    "\n",
    "#Assume seasons are defined as quarters (1-4)\n",
    "features_df['season_sin'] = np.sin(2 * np.pi * features_df.index.month % 12 / 4)\n",
    "features_df['season_cos'] = np.cos(2 * np.pi * features_df.index.month % 12 / 4)\n",
    "\n",
    "features_df['week_sin'] = np.sin(2 * np.pi * features_df.index.strftime('%U').astype(int) / 52)  # Assuming 52 weeks in a year\n",
    "features_df['week_cos'] = np.cos(2 * np.pi * features_df.index.strftime('%U').astype(int) / 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "726745b2-5e87-4c1c-aa6e-277c58da2530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9812, 171)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6349fe5d-5eb8-4763-9e4d-dd2cfc73088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add moonphase as a column (Code for moonphase taken from kaggle: https://www.kaggle.com/competitions/m5-forecasting-accuracy/discussion/154776)\n",
    "def get_moon_phase(d):  # 0=new, 4=full; 4 days/phase\n",
    "    diff = d - datetime(2001, 1, 1)\n",
    "    days = decimal.Decimal(diff.days) + (decimal.Decimal(diff.seconds) / decimal.Decimal(86400))\n",
    "    lunations = decimal.Decimal(\"0.20439731\") + (days * decimal.Decimal(\"0.03386319269\"))\n",
    "    phase_index = math.floor((lunations % decimal.Decimal(1) * decimal.Decimal(8)) + decimal.Decimal('0.5'))\n",
    "    return int(phase_index) & 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9000239-3b92-46f4-8f20-a7a356ee2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['moon_phase'] = features_df.index.map(get_moon_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ad14f8f-efc0-4e4d-b1db-a084627317a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/2594305688.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df['moon_phase_sin'] = np.sin(2 * np.pi * features_df['moon_phase'] / 8)\n",
      "/var/folders/h5/pnqm5hvd2vj1397_ck_gmtj00000gn/T/ipykernel_18479/2594305688.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features_df['moon_phase_cos'] = np.cos(2 * np.pi * features_df['moon_phase'] / 8)\n"
     ]
    }
   ],
   "source": [
    "#cyclic encode the moonphase as it is ordinal, then drop moon phase\n",
    "features_df['moon_phase_sin'] = np.sin(2 * np.pi * features_df['moon_phase'] / 8)\n",
    "features_df['moon_phase_cos'] = np.cos(2 * np.pi * features_df['moon_phase'] / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06a79bdb-67f3-46ab-aa92-e014bd9451aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df=features_df.drop('moon_phase', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9228fc54-a5b7-405d-be6e-ee3ba4ab96a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9812, 173)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56375f70-0add-46f8-8f42-672d23dee878",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c809e72-ee51-4647-a118-efa9ec1c82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4562ecb-f67f-4a48-b78c-84df39d2fae9",
   "metadata": {},
   "source": [
    "**Train Test Split**\n",
    "\n",
    "First a test train split will be done, on the datetime index. Since datetime index is in order 80% of the len of the data frame will be taken in order for the train set. TimeSeries Split will be used for cross validation from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86bb496b-b0f8-49a8-b630-7725219d37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split on date for train and test\n",
    "split_point = '2006-01-01'\n",
    "#filter data on split point\n",
    "train_xg= features_df.index < split_point\n",
    "test_xg = features_df.index >= split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57e40608-2052-4cdc-a157-e5ad4e871475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "X_train = features_df[train_xg].drop(['VTP$'],axis=1)\n",
    "y_train = features_df[train_xg]['VTP$']\n",
    "\n",
    "X_test = features_df[test_xg].drop(['VTP$'], axis=1)\n",
    "y_test = features_df[test_xg]['VTP$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0312a0a6-d244-4129-9074-3888bec000da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6159, 172)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "696709dc-da77-4e02-a336-cbe84bbbf579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3653, 172)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d667766-19fd-459b-84bf-e766f03b58e6",
   "metadata": {},
   "source": [
    "**Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fc1b0-d94c-42cb-b0e1-ed8bc0e63c41",
   "metadata": {},
   "source": [
    " **System Specifications and Parallelization**\n",
    "\n",
    "- **Model Name:** Mac mini\n",
    "- **Chip:** Apple M2\n",
    "- **Total Number of Cores:** 8 (4 performance and 4 efficiency)\n",
    "- **Memory:** 16 GB\n",
    "\n",
    "\n",
    "**Parallization**\n",
    "n_jobs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b160dad-95a6-4963-9eee-e93e85bacca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline object\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb_model',xgb.XGBRegressor(objective ='reg:squarederror',random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f71bd52-3d1d-4d14-a972-968e76dfa4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Param Grid\n",
    "param_grid_gbtree = {\n",
    "    'xgb_model__booster': ['gbtree'],\n",
    "    'xgb_model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb_model__max_depth': [3, 5, 7],\n",
    "    'xgb_model__n_estimators': [50, 100, 200],\n",
    "}\n",
    "\n",
    "# Param grid for gblinear booster\n",
    "param_grid_gblinear = {\n",
    "    'xgb_model__booster': ['gblinear'],\n",
    "    'xgb_model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb_model__reg_alpha': [0, 0.1, 0.5],\n",
    "}\n",
    "\n",
    "\n",
    "param_grid =[param_grid_gbtree, param_grid_gblinear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "188e2ef0-237a-45dc-9ff7-1e6751622b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamiasalango/anaconda3/envs/capstone_wavepower/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search completed in 41.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "#grid search\n",
    "#cv = sklearn TimeSeries Split\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "#set timer\n",
    "start_time = time.time()\n",
    "grid_search = GridSearchCV(xgb_pipeline, param_grid, cv=tscv, scoring='neg_mean_squared_error',n_jobs=3) #will optimize for smallest mse\n",
    "grid_search.fit(X_train, y_train)\n",
    "#end timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Grid search completed in {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1319fae7-7ea8-4555-bfce-905074360afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'xgb_model__booster': 'gbtree', 'xgb_model__learning_rate': 0.2, 'xgb_model__max_depth': 3, 'xgb_model__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#get the best params\n",
    "best_params = grid_search.best_params_\n",
    "print('Best Hyperparameters:')\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7224b9c2-184e-4e60-8c95-dc987dc2b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5e632-52e7-43b0-bb26-295d1f6efa85",
   "metadata": {},
   "source": [
    "Hyperparameters are at boundaries of ranges. Grid Search will be run again with an expanded hyperparameter space and just on gbtree as it was the best model. In future may come back to gblinear and try to optimize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f3c805b-bbce-400f-b96e-fb2cd8266bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use function for grid search\n",
    "def run_grid_search(X_train, y_train, param_grid, pipeline, scoring_metric, identifier):\n",
    "    \"\"\"\n",
    "    Run a grid search with the specified parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels\n",
    "    - param_grid: Parameter grid for the grid search\n",
    "    - pipeline: pipeline object\n",
    "    - scoring_metric: Scikit-learn scoring metric\n",
    "    - identifier: Identifier for iteration of Gridsearch'\n",
    "\n",
    "    Returns:\n",
    "    - grid_search: Fitted GridSearchCV object \n",
    "    -resluts of cross validation in terms of best params, best score (validation set)\n",
    "    - time it took to run GridSearch\n",
    "    \"\"\"\n",
    "    #initiate timer module\n",
    "    start_time = time.time()\n",
    "    #time series cv\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    # Set up the scoring metric\n",
    "    scoring = scoring_metric\n",
    "\n",
    "    # Instantiate GridSearchCV with 5-fold cross-validation, n_jobs=3, and specified scoring metric\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=tscv, scoring=scoring, n_jobs=3)\n",
    "\n",
    "    # Fit and run grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    #end timer\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "     # Store the results (hyperparameters and scores)\n",
    "    results_list.append({\n",
    "        'identifier': identifier,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'elapsed_time': elapsed_time\n",
    "    })\n",
    "    \n",
    "    # Print the best parameters with the identifier\n",
    "    print(f\"Best Parameters for {identifier}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Print the best score on the validation sets, \n",
    "    #.best_score_ is attribute of GridSearch CV that accesses best validation score(score specified in GS)\n",
    "    print(f\"Best {scoring_metric} Score for {identifier}: {grid_search.best_score_}\")\n",
    "    # Print the elapsed time\n",
    "    print(f\"Elapsed Time for {identifier}: {elapsed_time} seconds\")\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2d8f2-1c6d-4f4f-8fe8-fc38c8ef7b6d",
   "metadata": {},
   "source": [
    "**GridSearch run, Identifier = optimize_tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84a84b7a-c326-493f-b595-42627128af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run gridsearch with expanded params: \n",
    "param_grid_gbtree = {\n",
    "    'xgb_model__booster': ['gbtree'],\n",
    "    'xgb_model__learning_rate': [0.01, 0.1, 0.2, 0.5],  # Added 0.5\n",
    "    'xgb_model__max_depth': [2,3, 5, 7, 10],  # Added 2, 10\n",
    "    'xgb_model__n_estimators': [50, 100, 200, 300],  # Added 300\n",
    "    'xgb_model__subsample': [0.8, 0.9, 1.0],  # Add subsample\n",
    "    'xgb_model__colsample_bytree': [0.8, 0.9, 1.0],  # Add colsample_bytree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed36ee-f6db-4323-bb6f-ea9b33904862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamiasalango/anaconda3/envs/capstone_wavepower/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scoring_metric = 'neg_mean_squared_error'\n",
    "run_grid_search(X_train, y_train, param_grid_gbtree, xgb_pipeline, scoring_metric, 'optimize_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455823c4-4c2e-4037-938c-63193fc13ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_wavepower",
   "language": "python",
   "name": "capstone_wavepower"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
